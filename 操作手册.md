# 操作手册

本文档提供详细的使用说明、配置指南和故障排除方法。

## 目录

1. [环境准备](#环境准备)
2. [安装部署](#安装部署)
3. [配置说明](#配置说明)
4. [使用指南](#使用指南)
5. [API 文档](#api-文档)
6. [故障排除](#故障排除)
7. [性能优化](#性能优化)

## 环境准备

### 硬件要求

- **GPU**：NVIDIA RTX 3090 (24GB) 或更高配置
- **内存**：32GB+ 推荐
- **存储**：至少 50GB 可用空间（用于模型存储）

### 软件要求

- **操作系统**：Ubuntu 22.04 LTS (推荐) 或 Ubuntu 20.04+
- **Python**：3.9 或 3.10
- **CUDA**：11.8+ 或 12.0+
- **cuDNN**：与 CUDA 版本匹配
- **NVIDIA 驱动**：>= 525.60.13

### 检查环境

```bash
# 检查 Python 版本
python3 --version  # 应显示 3.9.x 或 3.10.x

# 检查 CUDA
nvidia-smi  # 应显示 GPU 信息和 CUDA 版本

# 检查 PyTorch CUDA 支持
python3 -c "import torch; print(torch.cuda.is_available())"  # 应输出 True
```

## 安装部署

### 1. 克隆项目

```bash
git clone <repository-url>
cd emo-voice-chat
```

### 2. 创建虚拟环境

```bash
# 创建虚拟环境
python3.9 -m venv venv

# 激活虚拟环境
source venv/bin/activate

# 确认激活成功（提示符前应显示 (venv)）
which python  # 应指向 venv/bin/python
```

### 3. 安装依赖

```bash
# 升级 pip
pip install --upgrade pip

# 安装依赖（可能需要 10-20 分钟）
pip install -r requirements.txt
```

**注意**：如果安装过程中遇到问题，请参考[故障排除](#故障排除)章节。

### 4. 下载模型

#### 方式一：自动下载（推荐）

首次运行时，模型会自动从 Hugging Face 或 ModelScope 下载。

**配置镜像站（国内用户推荐）**：

```bash
# 配置 Hugging Face 镜像
export HF_ENDPOINT=https://hf-mirror.com

# 配置 ModelScope 镜像（已在代码中默认使用）
```

#### 方式二：手动下载

**SenseVoice 模型**：
```bash
# 使用 ModelScope 下载
python -c "from modelscope import snapshot_download; snapshot_download('iic/SenseVoiceSmall', cache_dir='~/.cache/modelscope')"
```

**Qwen 模型**：
```bash
# 使用 Hugging Face CLI
huggingface-cli download Qwen/Qwen2.5-7B-Instruct --local-dir ./models/Qwen2.5-7B-Instruct
```

### 5. 部署 IndexTTS 服务（可选）

如果使用 IndexTTS 后端，需要单独部署服务：

```bash
# 参考 IndexTTS 官方文档部署
# 默认服务地址：http://localhost:8000/tts
```

如果使用 Coqui TTS 后端，则无需额外部署。

### 6. 验证安装

```bash
# 测试 STT
python -m src.tests.sensevoice_demo

# 测试 LLM
python -m src.tests.llm_demo

# 测试 TTS
python -m src.tests.tts_demo
```

## 配置说明

### 环境变量配置

创建 `.env` 文件（可选）：

```bash
# STT 配置
SENSEVOICE_MODEL_DIR=/path/to/SenseVoiceSmall
SENSEVOICE_DEVICE=cuda:0

# LLM 配置
LLM_MODEL_NAME=Qwen/Qwen2.5-7B-Instruct
LLM_LOAD_IN_4BIT=true
LLM_MAX_NEW_TOKENS=512
LLM_TEMPERATURE=0.7

# TTS 配置
TTS_BACKEND=indextts  # 可选：coqui, vits, indextts
INDEXTTS_SERVICE_URL=http://localhost:8000/tts
INDEXTTS_TIMEOUT=300

# 对话历史配置
MAX_HISTORY_TURNS=10
HISTORY_DIR=data/history
```

### 代码配置

#### STT 配置

编辑 `src/stt/sensevoice_engine.py`：

```python
DEFAULT_SENSEVOICE_MODEL_DIR = "/path/to/model"
DEFAULT_SENSEVOICE_DEVICE = "cuda:0"
```

#### LLM 配置

编辑 `src/llm/backends/config.py`：

```python
class LLMConfig:
    model_name_or_path = "Qwen/Qwen2.5-7B-Instruct"
    load_in_4bit = True
    max_new_tokens = 512
    temperature = 0.7
    # ... 其他配置
```

#### TTS 配置

编辑 `src/tts/config.py`：

```python
DEFAULT_BACKEND = "indextts"  # 或 "coqui", "vits"
INDEXTTS_SERVICE_URL = "http://localhost:8000/tts"
COQUI_MODEL_NAME = "tts_models/zh-CN/emotion-tts/vits"
```

### 情绪参数配置

编辑 `src/tts/config.py` 中的 `EMOTION_TTS_MAPPING` 可以调整不同情绪对应的语音参数：

```python
EMOTION_TTS_MAPPING = {
    EmotionLabel.HAPPY: EmotionTTSParams(
        speed=1.15,      # 语速（1.0为正常）
        pitch=0.15,      # 音高调整
        volume=1.0,      # 音量
        emotion_style="happy"
    ),
    # ... 其他情绪
}
```

## 使用指南

### 方式一：Web 服务（推荐）

#### 启动服务

```bash
# 激活虚拟环境
source venv/bin/activate

# 启动服务
uvicorn web_service:app --host 0.0.0.0 --port 8001

# 或使用 Python 模块方式
python -m uvicorn web_service:app --host 0.0.0.0 --port 8001
```

#### 访问界面

1. 打开浏览器访问：`http://localhost:8001`
2. 如果是远程服务器，访问：`http://<服务器IP>:8001`

#### 使用流程

1. **开始对话**：
   - 点击"开始录音"按钮
   - 对着麦克风说话
   - 点击"停止录音"

2. **查看结果**：
   - 对话历史会显示在界面上
   - 用户情绪会以标签形式显示
   - 助手回复会自动播放

3. **清除历史**：
   - 点击"清除历史"按钮
   - 确认后清除当前用户的所有对话记录

### 方式二：命令行交互

```bash
# 激活虚拟环境
source venv/bin/activate

# 运行命令行版本
python -m src.app.main
```

**使用说明**：
- 按回车开始录音
- 说话后自动停止（检测到静音）
- 输入 `q` 后回车退出

### 方式三：API 调用

#### Python 示例

```python
import requests

# 上传音频文件
with open("audio.wav", "rb") as f:
    files = {"file": f}
    data = {"user_id": "user_001"}  # 可选
    response = requests.post(
        "http://localhost:8001/api/voice-chat",
        files=files,
        data=data
    )
    result = response.json()
    print(result)
```

#### cURL 示例

```bash
# 发送语音请求
curl -X POST "http://localhost:8001/api/voice-chat" \
  -F "file=@audio.wav" \
  -F "user_id=user_001"

# 清除历史
curl -X DELETE "http://localhost:8001/api/clear-history" \
  -F "user_id=user_001"
```

## API 文档

### POST `/api/voice-chat`

语音对话接口。

**请求**：
- Content-Type: `multipart/form-data`
- `file` (必填): 音频文件（支持 wav, webm, ogg 等格式）
- `user_id` (可选): 用户ID，不提供则自动生成

**响应**：
```json
{
  "user_id": "user_001",
  "audio_base64": "UklGRiQAAABXQVZFZm10...",
  "user_text": "你好",
  "user_emotion": "neutral",
  "assistant_reply": "你好呀！有什么可以帮你的吗？",
  "assistant_emotion": "happy"
}
```

**状态码**：
- `200`: 成功
- `400`: 请求参数错误
- `500`: 服务器内部错误

### DELETE `/api/clear-history`

清除用户对话历史。

**请求**：
- Content-Type: `multipart/form-data`
- `user_id` (必填): 用户ID

**响应**：
```json
{
  "success": true,
  "message": "已清除用户 user_001 的所有数据",
  "result": {
    "user_id": "user_001",
    "deleted_files": ["data/history/user_001.json"],
    "deleted_dirs": ["data/web_input/user_001", "data/output_voice/user_001"],
    "total_files": 1,
    "total_dirs": 2
  }
}
```

### GET `/`

返回 Web 前端界面（index.html）。

## 故障排除

### 1. 显存不足 (OOM)

**症状**：运行时出现 `CUDA out of memory` 错误

**解决方案**：

```python
# 方案1：使用更小的模型
# 编辑 src/llm/backends/config.py
model_name_or_path = "Qwen/Qwen2.5-3B-Instruct"  # 使用 3B 模型

# 方案2：使用 8-bit 量化（显存占用更少，但速度稍慢）
load_in_4bit = False
load_in_8bit = True

# 方案3：使用 llama.cpp 后端（CPU推理）
backend_type = LLMBackendType.LLAMA_CPP
```

**临时方案**：
```bash
# 关闭其他占用显存的程序
# 重启服务
```

### 2. 模型下载失败

**症状**：首次运行时提示模型下载失败

**解决方案**：

```bash
# 方案1：配置镜像站
export HF_ENDPOINT=https://hf-mirror.com

# 方案2：手动下载
# 使用 Hugging Face CLI
pip install huggingface-hub
huggingface-cli download Qwen/Qwen2.5-7B-Instruct

# 方案3：使用 ModelScope（国内用户）
# 代码中已默认使用 ModelScope 下载 SenseVoice
```

### 3. IndexTTS 服务连接失败

**症状**：TTS 合成失败，提示连接错误

**解决方案**：

```bash
# 1. 检查服务是否启动
curl http://localhost:8000/tts

# 2. 检查配置
# 编辑 src/tts/config.py 或设置环境变量
export INDEXTTS_SERVICE_URL=http://localhost:8000/tts

# 3. 切换到其他 TTS 后端
export TTS_BACKEND=coqui
```

### 4. 音频格式转换失败

**症状**：上传 webm/ogg 文件后提示转换失败

**解决方案**：

```bash
# 安装 ffmpeg
sudo apt-get update
sudo apt-get install ffmpeg

# 验证安装
ffmpeg -version
```

### 5. 端口被占用

**症状**：启动服务时提示端口 8001 已被占用

**解决方案**：

```bash
# 方案1：使用其他端口
uvicorn web_service:app --host 0.0.0.0 --port 8002

# 方案2：查找并关闭占用端口的进程
lsof -i :8001
kill -9 <PID>
```

### 6. 依赖安装失败

**症状**：`pip install` 时某些包安装失败

**解决方案**：

```bash
# 方案1：升级 pip 和 setuptools
pip install --upgrade pip setuptools wheel

# 方案2：使用国内镜像源
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# 方案3：逐个安装（找出问题包）
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
```


### 移动端零时使用
```txt
下载chrome浏览器，其他浏览器不支持没有证书的权限
在手机 Chrome 浏览器地址栏输入：chrome://flags
在搜索框输入：Insecure origins treated as secure
将状态改为 Enabled。
在下方输入框填入你电脑的 IP 和端口，例如：http://192.168.1.100:8080（注意是 http，不是 https）。
点击底部的 “重启”（Relaunch）。
现在手机访问 http://192.168.1.100:8080 即可使用麦克风。
```


## 性能优化

### 1. 显存优化

```python
# 按需加载模型（在 pipeline.py 中实现）
# 非对话时段卸载模型
llm.unload()
tts.unload()

# 对话时再加载
llm = LLMEngine()
tts = TTSEngine()
```

### 2. 推理速度优化

```python
# 使用更快的量化方式
load_in_4bit = True  # 4-bit 比 8-bit 更快

# 调整生成参数
max_new_tokens = 256  # 减少生成长度
do_sample = False     # 使用贪心解码（更快）
```

### 3. 批量处理

```python
# 对于多个音频文件，可以批量处理
# 减少模型加载次数
```

### 4. 缓存优化

```python
# 对话历史缓存（已实现）
# 模型 KV 缓存（已启用）
use_cache = True
```

### 5. 系统优化

```bash
# 关闭不必要的服务
sudo systemctl stop <service-name>

# 设置 GPU 性能模式
sudo nvidia-smi -pm 1

# 限制其他进程的 GPU 使用
export CUDA_VISIBLE_DEVICES=0
```

## 数据管理

### 对话历史

- **位置**：`data/history/user_*.json`
- **格式**：JSON 格式，包含用户文本、情绪、助手回复等
- **清理**：通过 API 或手动删除文件

### 音频文件

- **输入**：`data/web_input/user_*/` - Web 上传的原始音频
- **输出**：`data/output_voice/user_*/` - TTS 生成的音频
- **清理**：定期清理旧文件以节省空间





